{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "\n",
    "from SmithZero import D2torchEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa402fc9d70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10 \n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# === data transformation === # \n",
    "train_T = T.Compose([   T.RandomCrop(32, padding=4),\n",
    "                        T.RandomHorizontalFlip(), \n",
    "                        T.ToTensor(), \n",
    "                        T.Normalize(mean= (0.4914, 0.4822, 0.4465),\n",
    "                                    std=(0.2023, 0.1994, 0.2010)),\n",
    "                    ])\n",
    "\n",
    "test_T = T.Compose([T.ToTensor(),\n",
    "                    T.Normalize(mean=(0.4914, 0.4822, 0.4465),\n",
    "                                std=(0.2023, 0.1994, 0.2010))\n",
    "                    ])                  \n",
    "\n",
    "\n",
    "# === download dataset object === # \n",
    "train_data = CIFAR10 (  root=\"./dataset/train\",\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=train_T )\n",
    "\n",
    "test_data = CIFAR10 (   root=\"./dataset/test\",\n",
    "                        train=False,\n",
    "                        download=True, \n",
    "                        transform=test_T )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batchSize = 124\n",
    "\n",
    "testloader = DataLoader(test_data,\n",
    "                        batch_size=batchSize,\n",
    "                        num_workers=4 \n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, n_class=10, p=0.5):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.p = p # probability for DropOut layer \n",
    "        \n",
    "        # === Create the convolution layers === # \n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5, padding=2)\n",
    "        self.c3 = nn.Conv2d(6, 16, 5) \n",
    "        self.c5 = nn.Conv2d(16, 120, 5) \n",
    "\n",
    "        # === Create the linear layers === # \n",
    "        self.f6 = nn.Linear(in_features=480, out_features=84)\n",
    "        self.output = nn.Linear(in_features=84, out_features=n_class)\n",
    "\n",
    "        # === Create dropout layers === # \n",
    "        self.drop = nn.Dropout(self.p)\n",
    "\n",
    "    def featurizer(self, x):\n",
    "        # === block1 === # \n",
    "        x = self.c1(x)\n",
    "        x = F.relu(x) \n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        # === block2 === # \n",
    "        x = self.c3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        # === block3 === # \n",
    "        x = self.c5(x)\n",
    "        x = F.relu(x)\n",
    "        # ==== flattening === #\n",
    "        x = nn.Flatten()(x)\n",
    "        return x \n",
    "\n",
    "    def classifier(self, x): \n",
    "        # === hidden layler === # \n",
    "        if self.p > 0: \n",
    "            x = self.drop(x)        \n",
    "        x = self.f6(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # === output layer === # \n",
    "        if self.p > 0 :\n",
    "            x = self.drop(x)\n",
    "        x = self.output(x)\n",
    "        return x \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.featurizer(x) # return (1, 480)\n",
    "        x = self.classifier(x) # return (1, 10)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet(in_channels=3, n_class=10, p=0.5)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD( model.parameters(), # (!) be sure to pass in the model.parameters() \n",
    "                        lr=1e-3, \n",
    "                        momentum=0.9,\n",
    "                    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milky/anaconda3/envs/py38/lib/python3.8/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "AgentDL = D2torchEngine(model, loss_fn, optimizer)  # init. your deep learning engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentDL.load_checkpoint('model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Multiclass Classifcation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_idx_0: 7/12\n",
      "cls_idx_1: 9/10\n",
      "cls_idx_2: 5/11\n",
      "cls_idx_3: 7/14\n",
      "cls_idx_4: 5/10\n",
      "cls_idx_5: 2/9\n",
      "cls_idx_6: 15/19\n",
      "cls_idx_7: 8/13\n",
      "cls_idx_8: 15/15\n",
      "cls_idx_9: 10/11\n",
      "Accuracy: 0.669\n"
     ]
    }
   ],
   "source": [
    "results = AgentDL.correct(inputs, labels)\n",
    "\n",
    "for cls_idx, (num_correct, num_items) in enumerate(results.tolist()):\n",
    "    print(f\"cls_idx_{cls_idx}: {num_correct}/{num_items}\")\n",
    "\n",
    "\n",
    "sum_correct = results[:,0].sum().item()\n",
    "total_items = results[:,1].sum().item()\n",
    "\n",
    "print(f\"Accuracy: {sum_correct/total_items:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "80.64516129032258\n"
     ]
    }
   ],
   "source": [
    "results = [AgentDL.correct(inputs, labels) for idx, (inputs, labels) in enumerate(testloader)]\n",
    "\n",
    "print(len(results))\n",
    "print(len(test_data)/ batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([81, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "results = torch.stack(results, axis=0)\n",
    "print(results.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_idx_0: 743/1000\n",
      "cls_idx_1: 921/1000\n",
      "cls_idx_2: 514/1000\n",
      "cls_idx_3: 457/1000\n",
      "cls_idx_4: 685/1000\n",
      "cls_idx_5: 563/1000\n",
      "cls_idx_6: 724/1000\n",
      "cls_idx_7: 764/1000\n",
      "cls_idx_8: 767/1000\n",
      "cls_idx_9: 774/1000\n",
      "Accuracy: 0.691\n"
     ]
    }
   ],
   "source": [
    "# Sum accuracy \n",
    "assemble = results.sum(axis=0)\n",
    "\n",
    "for idx, (n_correct, n_items) in enumerate(assemble.tolist()):\n",
    "    print(f\"cls_idx_{idx}: {n_correct}/{n_items}\")\n",
    "\n",
    "sum_correct = assemble[:,0].sum().item()\n",
    "total_items = assemble[:,1].sum().item()\n",
    "\n",
    "print(f\"Accuracy: {sum_correct/total_items:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_idx_0: 9.173/12.346\n",
      "cls_idx_1: 11.370/12.346\n",
      "cls_idx_2: 6.346/12.346\n",
      "cls_idx_3: 5.642/12.346\n",
      "cls_idx_4: 8.457/12.346\n",
      "cls_idx_5: 6.951/12.346\n",
      "cls_idx_6: 8.938/12.346\n",
      "cls_idx_7: 9.432/12.346\n",
      "cls_idx_8: 9.469/12.346\n",
      "cls_idx_9: 9.556/12.346\n",
      "Accuracy: 0.691\n"
     ]
    }
   ],
   "source": [
    "# Mean accuracy \n",
    "assemble = results.float().mean(axis=0)\n",
    "\n",
    "for idx, (n_correct, n_items) in enumerate(assemble.tolist()):\n",
    "    print(f\"cls_idx_{idx}: {n_correct:.3f}/{n_items:.3f}\")\n",
    "\n",
    "sum_correct = assemble[:,0].sum().item()\n",
    "total_items = assemble[:,1].sum().item()\n",
    "\n",
    "print(f\"Accuracy: {sum_correct/total_items:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classy - ([ref](https://github.com/dvgodoy/PyTorchStepByStep/blob/master/Chapter05.ipynb))\n",
    "* multiclass classfication accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "# add attribute test \n",
    "\n",
    "class TEST(object):\n",
    "    def __init__(self):\n",
    "        self.x = 10 \n",
    "\n",
    "# ----------\n",
    "def add_method():\n",
    "    print(\"hi\")\n",
    "\n",
    "\n",
    "test_model = TEST()\n",
    "setattr(test_model,'add_method', add_method)\n",
    "\n",
    "test_model.add_method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod \n",
    "def loader_apply(dataloader, func, reduce='sum'):\n",
    "    results = [func(inputs, labels) for idx, (inputs, labels) in enumerate(dataloader)]\n",
    "    results = torch.stack(results, axis=0)\n",
    "\n",
    "    if reduce == 'sum': \n",
    "        results = results.sum(axis=0)\n",
    "    elif reduce == 'mean': \n",
    "        results = results.float().mean(axis=0)\n",
    "\n",
    "    return results \n",
    "\n",
    "setattr(D2torchEngine, 'loader_apply', loader_apply) # add method attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 743, 1000],\n",
      "        [ 921, 1000],\n",
      "        [ 514, 1000],\n",
      "        [ 457, 1000],\n",
      "        [ 685, 1000],\n",
      "        [ 563, 1000],\n",
      "        [ 724, 1000],\n",
      "        [ 764, 1000],\n",
      "        [ 767, 1000],\n",
      "        [ 774, 1000]])\n",
      "cls_idx_0: 743/1000\n",
      "cls_idx_1: 921/1000\n",
      "cls_idx_2: 514/1000\n",
      "cls_idx_3: 457/1000\n",
      "cls_idx_4: 685/1000\n",
      "cls_idx_5: 563/1000\n",
      "cls_idx_6: 724/1000\n",
      "cls_idx_7: 764/1000\n",
      "cls_idx_8: 767/1000\n",
      "cls_idx_9: 774/1000\n",
      "tensor([ 6912, 10000])\n",
      "Accuracy: 0.691\n"
     ]
    }
   ],
   "source": [
    "AgentDL.set_loaders(train_loader=None, val_loader=testloader)\n",
    "\n",
    "results = D2torchEngine.loader_apply(AgentDL.val_loader, AgentDL.correct, reduce='sum')\n",
    "print(results)\n",
    "\n",
    "\n",
    "for idx, (n_correct, n_items) in enumerate(results.tolist()):\n",
    "    print(f\"cls_idx_{idx}: {n_correct}/{n_items}\")\n",
    "\n",
    "\n",
    "results = results.sum(axis=0)\n",
    "print(results)\n",
    "print(f\"Accuracy: {results[0]/results[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.1728, 12.3457],\n",
      "        [11.3704, 12.3457],\n",
      "        [ 6.3457, 12.3457],\n",
      "        [ 5.6420, 12.3457],\n",
      "        [ 8.4568, 12.3457],\n",
      "        [ 6.9506, 12.3457],\n",
      "        [ 8.9383, 12.3457],\n",
      "        [ 9.4321, 12.3457],\n",
      "        [ 9.4691, 12.3457],\n",
      "        [ 9.5556, 12.3457]])\n",
      "cls_idx_0: 9.173/12.346\n",
      "cls_idx_1: 11.370/12.346\n",
      "cls_idx_2: 6.346/12.346\n",
      "cls_idx_3: 5.642/12.346\n",
      "cls_idx_4: 8.457/12.346\n",
      "cls_idx_5: 6.951/12.346\n",
      "cls_idx_6: 8.938/12.346\n",
      "cls_idx_7: 9.432/12.346\n",
      "cls_idx_8: 9.469/12.346\n",
      "cls_idx_9: 9.556/12.346\n",
      "tensor([ 85.3333, 123.4568])\n",
      "Accuracy: 0.691\n"
     ]
    }
   ],
   "source": [
    "AgentDL.set_loaders(train_loader=None, val_loader=testloader)\n",
    "\n",
    "results = D2torchEngine.loader_apply(AgentDL.val_loader, AgentDL.correct, reduce='mean')\n",
    "print(results)\n",
    "\n",
    "\n",
    "for idx, (n_correct, n_items) in enumerate(results.tolist()):\n",
    "    print(f\"cls_idx_{idx}: {n_correct:.3f}/{n_items:.3f}\")\n",
    "\n",
    "\n",
    "results = results.sum(axis=0)\n",
    "print(results)\n",
    "print(f\"Accuracy: {results[0]/results[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
