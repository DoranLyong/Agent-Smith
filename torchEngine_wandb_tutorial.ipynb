{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "\n",
    "from SmithZero import D2torchEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd8cd4c1d70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === hyperparameter dict === # \n",
    "# you can receive with .yaml or .json \n",
    "\n",
    "hyperparams = dict(\n",
    "        seed=42, \n",
    "        epochs=50,\n",
    "        classes=10,\n",
    "        batch_size=128,\n",
    "        n_workers=4,\n",
    "        learning_rate=7e-3,\n",
    "        dataset=\"CIFAR10\",\n",
    "        architecture=\"LeNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W&B setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdoranlyong\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb \n",
    "\n",
    "wandb.login() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milky/anaconda3/envs/py38/lib/python3.8/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/doranlyong/LeNet-cifar10/runs/2zvtf24q\" target=\"_blank\">crimson-breeze-15</a></strong> to <a href=\"https://wandb.ai/doranlyong/LeNet-cifar10\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 214748... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">crimson-breeze-15</strong>: <a href=\"https://wandb.ai/doranlyong/LeNet-cifar10/runs/2zvtf24q\" target=\"_blank\">https://wandb.ai/doranlyong/LeNet-cifar10/runs/2zvtf24q</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211208_140453-2zvtf24q/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "proj_name = \"LeNet-cifar10\"\n",
    "\n",
    "wandb.init(project=proj_name, config=hyperparams)\n",
    "config = wandb.config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10 \n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# === data transformation === # \n",
    "train_T = T.Compose([   T.RandomCrop(32, padding=4),\n",
    "                        T.RandomHorizontalFlip(), \n",
    "                        T.ToTensor(), \n",
    "                        T.Normalize(mean= (0.4914, 0.4822, 0.4465),\n",
    "                                    std=(0.2023, 0.1994, 0.2010)),\n",
    "                    ])\n",
    "\n",
    "test_T = T.Compose([T.ToTensor(),\n",
    "                    T.Normalize(mean=(0.4914, 0.4822, 0.4465),\n",
    "                                std=(0.2023, 0.1994, 0.2010))\n",
    "                    ])                  \n",
    "\n",
    "\n",
    "# === download dataset object === # \n",
    "train_data = CIFAR10 (  root=\"./dataset/train\",\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=train_T )\n",
    "\n",
    "test_data = CIFAR10 (   root=\"./dataset/test\",\n",
    "                        train=False,\n",
    "                        download=True, \n",
    "                        transform=test_T )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Batching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainloader = DataLoader(train_data,\n",
    "                        batch_size=config.batch_size,\n",
    "                        shuffle=True, \n",
    "                        num_workers=config.n_workers \n",
    "                        )\n",
    "\n",
    "testloader = DataLoader(test_data,\n",
    "                        batch_size=config.batch_size,\n",
    "                        num_workers=config.n_workers \n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, n_class=10, p=0.5):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.p = p # probability for DropOut layer \n",
    "        \n",
    "        # === Create the convolution layers === # \n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5, padding=2)\n",
    "        self.c3 = nn.Conv2d(6, 16, 5) \n",
    "        self.c5 = nn.Conv2d(16, 120, 5) \n",
    "\n",
    "        # === Create the linear layers === # \n",
    "        self.f6 = nn.Linear(in_features=480, out_features=84)\n",
    "        self.output = nn.Linear(in_features=84, out_features=n_class)\n",
    "\n",
    "        # === Create dropout layers === # \n",
    "        self.drop = nn.Dropout(self.p)\n",
    "\n",
    "    def featurizer(self, x):\n",
    "        # === block1 === # \n",
    "        x = self.c1(x)\n",
    "        x = F.relu(x) \n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        # === block2 === # \n",
    "        x = self.c3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        # === block3 === # \n",
    "        x = self.c5(x)\n",
    "        x = F.relu(x)\n",
    "        # ==== flattening === #\n",
    "        x = nn.Flatten()(x)\n",
    "        return x \n",
    "\n",
    "    def classifier(self, x): \n",
    "        # === hidden layler === # \n",
    "        if self.p > 0: \n",
    "            x = self.drop(x)        \n",
    "        x = self.f6(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # === output layer === # \n",
    "        if self.p > 0 :\n",
    "            x = self.drop(x)\n",
    "        x = self.output(x)\n",
    "        return x \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.featurizer(x) # return (1, 480)\n",
    "        x = self.classifier(x) # return (1, 10)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet(in_channels=3, n_class=config.classes, p=0.5)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD( model.parameters(), # (!) be sure to pass in the model.parameters() \n",
    "                        lr=config.learning_rate, \n",
    "                        momentum=0.9,\n",
    "                    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milky/anaconda3/envs/py38/lib/python3.8/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/doranlyong/LeNet-cifar10/runs/5a1lds9k\" target=\"_blank\">dandy-eon-16</a></strong> to <a href=\"https://wandb.ai/doranlyong/LeNet-cifar10\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AgentDL = D2torchEngine(model, loss_fn, optimizer)  # init. your deep learning engine \n",
    "\n",
    "AgentDL.set_loaders(trainloader, testloader)  # init. engine with dataloader \n",
    "AgentDL.set_wandb(wandb, proj_name)  # set wandb on the engine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "140569064814928\n",
      "140569064814928\n"
     ]
    }
   ],
   "source": [
    "# check if the wandb wet well \n",
    "# are those the same? \n",
    "\n",
    "print(AgentDL.wandb == wandb) \n",
    "print(id(AgentDL.wandb))\n",
    "print(id(wandb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 4/50 [00:19<03:45,  4.89s/it]"
     ]
    }
   ],
   "source": [
    "# Run trianing \n",
    "AgentDL.train(n_epochs=config.epochs, seed=config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = AgentDL.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f38f9a92a40eacf7671051530596ac31a08fa1747600811db2b78ca4cf9fd4a6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
